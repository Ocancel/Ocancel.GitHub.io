[{"content":"根据表名查询pid列表 1 2 3 4 5 select locks.pid from pg_locks locks inner join pg_class class on locks.relation = class.oid where class.relname = \u0026#39;table_name\u0026#39;; 使用终止函数终止pid 1 select pg_terminate_backend(pid); ","date":"2023-05-24T20:09:29+08:00","permalink":"https://Ocancel.GitHub.io/post/postgresql-lock-table/","title":"PostgreSQL 锁表解决方案"},{"content":"Dynamic-Datasource 在pom.xml中导入依赖 1 2 3 4 \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;com.baomidou\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;dynamic-datasource-spring-boot-starter\u0026lt;/artifactId\u0026gt; \u0026lt;/dependency\u0026gt; 在application.yml中配置动态数据源 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 spring: datasource: dynamic: # 设置默认的数据源或者数据源组,默认值即为main primary: main # 严格匹配数据源,默认false. true未匹配到指定数据源时抛异常,false使用默认数据源 strict: false datasource: # 默认数据源 main: url: url username: username password: passward driver-class-name: xxx.Dirver # 其他数据源 slave_1: url: url username: username password: passward driver-class-name: xxx.Dirver 在Service方法上使用@DS注解 1 2 3 4 5 6 7 8 9 10 11 12 13 public interface DemoService { void testDynamicFunc(); } @Service public class DemoServiceImpl implements DemoService { @Override @DS(\u0026#34;main\u0026#34;) @Transactional(rollbackFor = Exception.class, isolation = Isolation.DEFAULT, propagation = Propagation.REQUIRES_NEW) void testDynamicFunc() { demoDao.batchInsertOrUpdate(List\u0026lt;Object\u0026gt; record); } } PS：在使用@DS注解时，需要注意以下两点\n在同一个Service类中，使用多个@DS注解配置不同的数据源，可能会失效，解决办法是不同数据源拆分成不同的Service类。 在同一个事务中，使用多个@DS注解配置不同的数据源，可能会失效，解决办法是将事务的传播方式修改为propagation = Propagation.REQUIRES_NEW ","date":"2023-04-05T19:19:15+08:00","permalink":"https://Ocancel.GitHub.io/post/springboot-dynamic-datasource/","title":"Springboot Dynamic Datasource"},{"content":"简介 MVCC全称Multi-Version Concurrency Control，即多版本并发控制。MVCC是一种并发控制的方法，一般在数据库管理系统中，实现对数据库的并发访问，在编程语言中实现事务内存。\n多版本并发控制：指的是一种高并发技术。最早的数据库系统，只有读读之间可以并发，读写，写读，写写都要阻塞。引入多版本之后，只有写写之间相互阻塞，其他三种操作都可以并行，这样大幅度提高了InnoDB的并发度。在内部实现中，InnoDB是基于undo log实现的，通过undo log可以找回数据的历史版本。找回的数据历史版本可以提供给用户读（按照隔离级别的定义，有些读请求只能看到比较老的数据版本），也可以在回滚的时候覆盖数据页上的数据。在InnoDB内部中，会记录一个全局的活跃读写事务数组，其主要用来判断事务的可见性。\nMVCC是一种多版本并发控制机制。\n前置知识 InnoDB的当前读和快照读 当前读：读取的记录是最新版本，读取时要保证其他事务不能修改当前记录，会对读取的记录进行加锁。 当前读主要包含以下场景\n共享锁：select ... lock in share mode 排他锁：select for update，insert，update，delete 快照读：不加锁的select操作属于快照读，即不加锁的非阻塞读。快照读基于多版本并发控制实现，即MVCC，正因为如此，可能导致快照读读取到的数据不是最新版本。 快照读的前提是事务的隔离级别不是串行级别，串行级别下快照读会退化成当前读。\nMVCC就是为了实现读-写冲突不加锁，而这个读指的就是快照读，而非当前读，当前读实际上是一种加锁的操作，是悲观锁的实现。\n数据库的并发场景 读-读：不存在线程安全问题，不需要并发控制。 读-写：存在线程安全问题，可能会造成事务隔离性问题，可能遇到脏读，幻读，不可重复读 写-写：存在线程安全问题，可能会存在更新丢失问题，如第一类更新丢失，第二类更新丢失 第一类更新丢失：事务A撤销时，把已经提交的事务B的更新数据覆盖。 第二类更新丢失：事务A覆盖事务B已经提交的数据，造成事务B所做的操作丢失。 实现原理 MVCC主要依赖记录中的三个隐式字段、undo log、Read View来实现的。\n隐式字段 每行记录除了我们自定义的字段外，还有数据库隐式定义的DB_TRX_ID，DB_ROLL_PTR，DB_ROW_ID等字段\nDB_TRX_ID：6byte， 最后修改（插入/更新）的事务ID DB_ROLL_PTR：7byte，回滚指针，配合undo log指向上一个版本的记录（存储于rollback segment） DB_ROW_ID：6byte，隐含的自增ID（隐藏主键），如果数据表没有主键，InnoDB会自动以DB_ROW_ID产生一个聚簇索引 Column1 Column2 DB_TRX_ID DB_ROW_ID DB_ROLL_PTR value1 value2 1 1 0x12446462 undo日志 insert undo log：事务在insert新记录时产生的undo log，只在事务回滚时需要，并且在事务提交后可以被立即丢弃。 update undo log：事务在进行update或delete时产生的undo log，不仅在事务回滚时需要，在快照读时也需要，所以不能随便删除，只有在快速读或事务回滚不涉及该日志时，对应的日志才会被purge线程统一清除。 purge\n为了实现InnoDB的MVCC机制，更新或者删除操作都只是设置一下老记录的deleted_bit，并不真正将过时的记录删除。 为了节省磁盘空间，InnoDB有专门的purge线程来清理deleted_bit为true的记录。为了不影响MVCC的正常工作，purge线程自己也维护了一个read view（这个read view相当于系统中最老活跃事务的read view），如果某个记录的deleted_bit为true，并且DB_TRX_ID相对于purge线程的read view可见，那么这条记录一定是可以被安全清除的。 MVCC依赖于update undo log，undo log实际上就是存在rollback segment中旧记录链。\nRead View Read View是事务进行快照读操作时生产的读视图Read View，在该事务执行快照读的那一刻，会生成数据库系统当前的一个快照，记录并维护系统当前活跃事务的ID（当每个事务开启时，都会被分配一个ID, 这个ID是递增的，所以最新的事务，ID值越大）。\nRead View主要是用来做可见性判断，Read View遵循一个可见性算法，主要是将要被修改的数据的最新记录中的DB_TRX_ID（即当前事务ID）取出来，与系统当前其他活跃事务的ID去对比（由Read View维护），如果DB_TRX_ID跟Read View的属性做了某些比较，不符合可见性，那就通过DB_ROLL_PTR回滚指针去取出undo Log中的DB_TRX_ID再比较，即遍历链表的DB_TRX_ID（从链首到链尾，即从最近的一次修改查起），直到找到满足特定条件的DB_TRX_ID，那么这个DB_TRX_ID所在的旧记录就是当前事务能看见的最新老版本。\n","date":"2022-06-01T22:59:43+08:00","permalink":"https://Ocancel.GitHub.io/post/mysql-mvcc/","title":"MySQL MVCC"},{"content":"简介 显示文件的最后一部分\n语法 1 tail [OPTION] FILE... 选项 1 2 3 4 5 6 7 8 9 10 11 -c, --bytes=NUM # 输出文件尾部的NUM（NUM为整数）个字节内容。 -f, --follow[={name|descript}] # 显示文件最新追加的内容。“name”表示以文件名的方式监视文件的变化。 -F # 与 “--follow=name --retry” 功能相同。 -n, --line=NUM # 输出文件的尾部NUM（NUM位数字）行内容。 --pid=\u0026lt;进程号\u0026gt; # 与“-f”选项连用，当指定的进程号的进程终止后，自动退出tail命令。 -q, --quiet, --silent # 当有多个文件参数时，不输出各个文件名。 --retry # 即是在tail命令启动时，文件不可访问或者文件稍后变得不可访问，都始终尝试打开文件。使用此选项时需要与选项“--follow=name”连用。 -s, --sleep-interal=\u0026lt;秒数\u0026gt; # 与“-f”选项连用，指定监视文件变化时间隔的秒数。 -v, --verbose # 当有多个文件参数时，总是输出各个文件名。 --help # 显示指令的帮助信息。 --version # 显示指令的版本信息。 参数 文件列表：指定要显示尾部内容的文件列表。\n补充说明 默认在屏幕上显示指定文件的末尾10行。 处理多个文件时会在各个文件之前附加含有文件名的行。 如果没有指定文件或者文件名为-，则读取标准输入。 如果表示字节或行数的NUM值之前有一个+号，则从文件开头的第NUM项开始显示，而不是显示文件的最后NUM项。 NUM值后面可以写单位： b：512 kB：1000 k：1024 MB：10002 M：10242 GB：10003 G：10243 T、P、E、Z、Y等以此类推。 ","date":"2022-03-04T21:12:03+08:00","permalink":"https://Ocancel.GitHub.io/post/linux-tail/","title":"Linux Tail"},{"content":"简介 Bean的生命周期主要包含实例化、属性注入、初始化、使用和销毁几个阶段。\nBean的生命周期 简略描述 Spring启动，查找并加载需要被Spring管理的bean，进行Bean的实例化。 Bean实例化后对将Bean的引入和值注入到Bean的属性中。 如果Bean实现了BeanNameAware接口，Spring将Bean的Id传递给setBeanName()方法。 如果Bean实现了BeanFactoryAware接口，Spring将调用setBeanFactory()方法，将BeanFactory容器实例传入。 如果Bean实现了ApplicationContextAware接口的话，Spring将调用Bean的setApplicationContext()方法，将Bean所在应用上下文引用传入。 如果Bean实现了BeanPostProcessor接口，Spring就将调用他们的postProcessBeforeInitialization()方法。 如果Bean实现了InitializingBean接口，Spring将调用他们的afterPropertiesSet()方法。 如果Bean使用init-method声明了初始化方法，该方法也会被调用。 如果Bean实现了BeanPostProcessor接口，Spring就将调用他们的postProcessAfterInitialization()方法。 Bean已经准备就绪，可以被应用程序使用了。Bean将一直驻留在应用上下文中，直到应用上下文被销毁。 如果bean实现了DisposableBean接口，Spring将调用它的destroy()接口方法。 如果bean使用了destroy-method声明销毁方法，该方法也会被调用。 完整的生命周期 初始化 BeanNameAware.setBeanName()：在创建此Bean的Bean工厂中设置Bean的名称，在普通属性设置之后调用，在InitializinngBean.afterPropertiesSet()方法之前调用。 BeanClassLoaderAware.setBeanClassLoader()：在普通属性设置之后，InitializingBean.afterPropertiesSet()之前调用。 BeanFactoryAware.setBeanFactory()：回调提供了自己的Bean实例工厂，在普通属性设置之后，在InitializingBean.afterPropertiesSet()或者自定义初始化方法之前调用。 EnvironmentAware.setEnvironment()：设置environment在组件使用时调用。 EmbeddedValueResolverAware.setEmbeddedValueResolver()：设置StringValueResolver 用来解决嵌入式的值域问题。 ResourceLoaderAware.setResourceLoader()：在普通bean对象之后调用，在afterPropertiesSet或者自定义的init-method之前调用，在ApplicationContextAware之前调用。 ApplicationEventPublisherAware.setApplicationEventPublisher()：在普通Bean属性之后调用，在初始化调用afterPropertiesSet或者自定义初始化方法之前调用。在ApplicationContextAware之前调用。 MessageSourceAware.setMessageSource()：在普通bean属性之后调用，在初始化调用afterPropertiesSet或者自定义初始化方法之前调用，在ApplicationContextAware之前调用。 ApplicationContextAware.setApplicationContext()：在普通Bean对象生成之后调用，在InitializingBean.afterPropertiesSet之前调用或者用户自定义初始化方法之前。在ResourceLoaderAware.setResourceLoader，ApplicationEventPublisherAware.setApplicationEventPublisher，MessageSourceAware之后调用。 ServletContextAware.setServletContext()：运行时设置ServletContext，在普通Bean初始化后调用，在InitializingBean.afterPropertiesSet之前调用，在 ApplicationContextAware 之后调用。 注：是在WebApplicationContext 运行时\nBeanPostProcessor.postProcessBeforeInitialization()：将此BeanPostProcessor应用于给定的新Bean实例，在任何Bean初始化回调方法（像是InitializingBean.afterPropertiesSet或者自定义的初始化方法）之前调用。这个Bean将要准备填充属性的值。返回的Bean示例可能被普通对象包装，默认实现返回是一个Bean。 BeanPostProcessor.postProcessAfterInitialization()： 将此BeanPostProcessor应用于给定的新Bean实例，在任何Bean初始化回调方法（像是InitializingBean.afterPropertiesSet或者自定义的初始化方法）之后调用。这个Bean将要准备填充属性的值。返回的Bean示例可能被普通对象包装。 InitializingBean.afterPropertiesSet()：被BeanFactory在设置所有Bean属性之后调用（并且满足BeanFactory和ApplicationContextAware）。 销毁 DestructionAwareBeanPostProcessor.postProcessBeforeDestruction()：在销毁之前将此BeanPostProcessor应用于给定的Bean实例。能够调用自定义回调，像是DisposableBean的销毁和自定义销毁方法，这个回调仅仅适用于工厂中的单例Bean（包括内部Bean） 实现了自定义的destory()方法。 ","date":"2021-09-07T11:38:44+08:00","image":"https://cdn.jsdelivr.net/gh/Vcancel/uPicRepo@main/uPic/Bean的生命周期.png","permalink":"https://Ocancel.GitHub.io/post/spring-bean-lifecycle/","title":"Spring Bean Lifecycle"},{"content":"简介 HashMap根据键的hashCode值存储数据，大多数情况下可以直接定位到它的值，因而具有很快的访问速度，但遍历顺序却是不确定的。 HashMap最多只允许一条记录的键为null，允许多条记录的值为null。HashMap非线程安全，即任一时刻可以有多个线程同时写HashMap，可能会导致数据的不一致。如果需要满足线程安全，可以用 Collections的synchronizedMap方法使HashMap具有线程安全的能力，或者使用ConcurrentHashMap。\n结构 JDK1.8以上的HashMap采用的是数组+链表+红黑树结构实现的。\nHashMap类内部维护了一个哈希桶数组，它是一个Node的数组，采用静态内部类Node来实现 1 2 3 4 5 6 7 8 9 10 11 12 13 static class Node\u0026lt;K,V\u0026gt; implements Map.Entry\u0026lt;K,V\u0026gt; { final int hash; //用来定位数组索引位置 final K key; V value; Node\u0026lt;K,V\u0026gt; next; //链表的下一个node Node(int hash, K key, V value, Node\u0026lt;K,V\u0026gt; next) { ... } public final K getKey(){ ... } public final V getValue() { ... } public final String toString() { ... } public final int hashCode() { ... } public final V setValue(V newValue) { ... } public final boolean equals(Object o) { ... } } HashMap就是使用哈希表来存储的。为了解决哈希冲突，Java中的HashMap采用链地址法来解决，即哈希桶数组的每个元素上都是链表结构。 当链表长度太长（默认超过8）时，链表就转换为红黑树，利用红黑树快速增删改查的特点提高HashMap的性能，其中会用到红黑树的插入、删除、查找等算法。 实现 HashMap的内部功能实现有很多，主要分析获取索引、 put方法和扩容机制三个方面的实现。\n获取索引 获取索引主要采用以下方法来实现。\n计算key的hashCode值：h = key.hashCode() 高位运算：h ^ (h \u0026gt;\u0026gt;\u0026gt; 16) 取模运算：h \u0026amp; (length - 1) 其中length代表哈希桶数组的长度\nput方法 HashMap的put方法执行过程可以通过下图来理解 put方法过程 判断键值对数组table[i]是否为空或为null，否则执行resize()进行扩容； 根据键值key计算hash值得到插入的数组索引i，如果table[i]为null，直接新建节点添加，转向6，如果table[i]不为空，转向3； 判断table[i]的首个元素是否和key一样，如果相同直接覆盖value，否则转向4，这里的相同指的是hashCode以及equals； 判断table[i] 是否为treeNode，即table[i] 是否是红黑树，如果是红黑树，则直接在树中插入键值对，否则转向5； 遍历table[i]，判断链表长度是否大于8，大于8的话把链表转换为红黑树，在红黑树中执行插入操作，否则进行链表的插入操作；遍历过程中若发现key已经存在直接覆盖value即可； 插入成功后，判断实际存在的键值对数量size是否超多了最大容量threshold，如果超过，进行扩容。 附JDK1.8HashMap的put方法源码 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 public V put(K key, V value) { // 对key的hashCode()做hash return putVal(hash(key), key, value, false, true); } final V putVal(int hash, K key, V value, boolean onlyIfAbsent, boolean evict) { Node\u0026lt;K, V\u0026gt;[] table; Node\u0026lt;K, V\u0026gt; p; int n, i; // 步骤1：tab为空则创建 if ((tab = table) == null || (n = tab.length) == 0) n = (tab = resize()).length; // 步骤2：计算index，并对null做处理 if ((p = tab[i = (n - 1) \u0026amp; hash]) == null) tab[i] = newNode(hash, key, value, null); else { Node\u0026lt;K, V\u0026gt; e; K k; // 步骤3：节点key存在，直接覆盖value if (p.hash == hash \u0026amp;\u0026amp; ((k = p.key) == key || (key != null \u0026amp;\u0026amp; key.equals(k)))) e = p; // 步骤4：判断该链为红黑树 else if (p instanceof TreeNode) e = ((TreeNode\u0026lt;K, V\u0026gt;)p).pututTreeVal(this, tab, hash, key, value); // 步骤5：该链为链表 else { for (int binCount = 0; ; ++binCount) { if ((e = p.next) == null) { p.next = newNode(hash, key,value,null); //链表长度大于8转换为红黑树进行处理 if (binCount \u0026gt;= TREEIFY_THRESHOLD - 1) treeifyBin(tab, hash); break; } // key已经存在直接覆盖value if (e.hash == hash \u0026amp;\u0026amp; ((k = e.key) == key || (key != null \u0026amp;\u0026amp; key.equals(k)))) break; p = e; } } if (e != null) { // existing mapping for key V oldValue = e.value; if (!onlyIfAbsent || oldValue == null) e.value = value; afterNodeAccess(e); return oldValue; } } ++modCount; // 步骤6：超过最大容量 就扩容 if (++size \u0026gt; threshold) resize(); afterNodeInsertion(evict); return null; } 扩容机制 当HashMap中包含的Entry的数量大于等于threshold = loadFactor * capacity的时候，且新建的Entry刚好落在一个非空的桶上，此刻触发扩容机制，将其容量扩大为2倍。\n其中threshold代表元素的数量阈值，laodFactor代表HashMap的负载因子，默认为0.75，capacity代表哈希桶数组的长度。\n由于Java中的数组无法自动扩容，所以扩容的方法是使用一个新的数组代替已有的容量小的数组。 以下是JDK1.8中的扩容源码\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 final Node\u0026lt;K,V\u0026gt;[] resize() { Node\u0026lt;K,V\u0026gt;[] oldTab = table; int oldCap = (oldTab == null) ? 0 : oldTab.length; int oldThr = threshold; int newCap, newThr = 0; if (oldCap \u0026gt; 0) { // 超过最大值就不再扩充了，就只好随你碰撞去吧 if (oldCap \u0026gt;= MAXIMUM_CAPACITY) { threshold = Integer.MAX_VALUE; return oldTab; } // 没超过最大值，就扩充为原来的2倍 else if ((newCap = oldCap \u0026lt;\u0026lt; 1) \u0026lt; MAXIMUM_CAPACITY \u0026amp;\u0026amp; oldCap \u0026gt;= DEFAULT_INITIAL_CAPACITY) newThr = oldThr \u0026lt;\u0026lt; 1; // double threshold } else if (oldThr \u0026gt; 0) // initial capacity was placed in threshold newCap = oldThr; else { // zero initial threshold signifies using defaults newCap = DEFAULT_INITIAL_CAPACITY; newThr = (int)(DEFAULT_LOAD_FACTOR * DEFAULT_INITIAL_CAPACITY); } // 计算新的resize上限 if (newThr == 0) { float ft = (float)newCap * loadFactor; newThr = (newCap \u0026lt; MAXIMUM_CAPACITY \u0026amp;\u0026amp; ft \u0026lt; (float)MAXIMUM_CAPACITY ? (int)ft : Integer.MAX_VALUE); } threshold = newThr; @SuppressWarnings({\u0026#34;rawtypes\u0026#34;，\u0026#34;unchecked\u0026#34;}) Node\u0026lt;K,V\u0026gt;[] newTab = (Node\u0026lt;K,V\u0026gt;[])new Node[newCap]; table = newTab; if (oldTab != null) { // 把每个bucket都移动到新的buckets中 for (int j = 0; j \u0026lt; oldCap; ++j) { Node\u0026lt;K,V\u0026gt; e; if ((e = oldTab[j]) != null) { oldTab[j] = null; if (e.next == null) newTab[e.hash \u0026amp; (newCap - 1)] = e; else if (e instanceof TreeNode) ((TreeNode\u0026lt;K,V\u0026gt;)e).split(this, newTab, j, oldCap); else { // 链表优化重hash的代码块 Node\u0026lt;K,V\u0026gt; loHead = null, loTail = null; Node\u0026lt;K,V\u0026gt; hiHead = null, hiTail = null; Node\u0026lt;K,V\u0026gt; next; do { next = e.next; // 原索引 if ((e.hash \u0026amp; oldCap) == 0) { if (loTail == null) loHead = e; else loTail.next = e; loTail = e; } // 原索引+oldCap else { if (hiTail == null) hiHead = e; else hiTail.next = e; hiTail = e; } } while ((e = next) != null); // 原索引放到bucket里 if (loTail != null) { loTail.next = null; newTab[j] = loHead; } // 原索引+oldCap放到bucket里 if (hiTail != null) { hiTail.next = null; newTab[j + oldCap] = hiHead; } } } } } return newTab; } 线程安全性 在多线程使用场景中，应该尽量避免使用线程不安全的HashMap，而使用线程安全的ConcurrentHashMap，在并发的多线程使用场景中使用HashMap可能造成死循环。\n","date":"2021-01-21T16:24:46+08:00","image":"https://cdn.jsdelivr.net/gh/Vcancel/uPicRepo@main/uPic/HashMap的put流程.png","permalink":"https://Ocancel.GitHub.io/post/java-hashmap/","title":"Java HashMap"},{"content":"当在命令行用ls -l命令查看文件列表的时候，看到文件权限后面有一个@符号，这说明该文件带有附加属性。\n1 2 3 4 --- ~ » ls -l total 0 drwx------@ 3 user staff 96 8 28 15:57 Applications drwx------@ 4 user staff 128 10 13 09:18 Desktop 查看某文件的附加属性 xattr -l filename 删除某文件的附加属性 xattr -c filename 删除某目录下所有文件、目录的附加属性 xattr -c -r path ","date":"2020-09-16T19:41:21+08:00","permalink":"https://Ocancel.GitHub.io/post/macos-additional-attribute/","title":"macOS 文件附加属性"},{"content":" 准备一个1024 * 1024的png图片，假设名字为pic.png\n命令行mkdir tmp.iconset，创建一个临时目录存放不同大小的图片\n把原图片转为不同大小的图片，并放入上面的临时目录\n全部拷贝到命令行回车执行，执行结束之后去tmp.iconset查看十张图片是否生成好\n1 2 3 4 5 6 7 8 9 10 sips -z 16 16 pic.png --out tmp.iconset/icon_16x16.png sips -z 32 32 pic.png --out tmp.iconset/icon_16x16@2x.png sips -z 32 32 pic.png --out tmp.iconset/icon_32x32.png sips -z 64 64 pic.png --out tmp.iconset/icon_32x32@2x.png sips -z 128 128 pic.png --out tmp.iconset/icon_128x128.png sips -z 256 256 pic.png --out tmp.iconset/icon_128x128@2x.png sips -z 256 256 pic.png --out tmp.iconset/icon_256x256.png sips -z 512 512 pic.png --out tmp.iconset/icon_256x256@2x.png sips -z 512 512 pic.png --out tmp.iconset/icon_512x512.png sips -z 1024 1024 pic.png --out tmp.iconset/icon_512x512@2x.png 通过iconutil生成icns文件iconutil -c icns tmp.iconset -o Icon.icns\n生成的Icon.icns就是图标文件\n","date":"2020-08-30T14:03:41+08:00","permalink":"https://Ocancel.GitHub.io/post/macos-icon/","title":"macOS icon"},{"content":"文件／目录 的权限包括： 权限 英文 缩写 数字代码 读 read r 4 写 write w 2 执行 execute x 1 文件／目录 的权限格式：-rwxrwxrwx 第一个符号代表文件类型，\u0026quot;-\u0026quot; 符号表示该文件是非目录类型，\u0026ldquo;d\u0026rdquo; 符号表示目录类型。\n没有相应权限则使用 “-” 符号替代。\n文件／目录 的权限详解： 类型 类型符号 拥有者权限 [user] 所在组权限[group] 其他用户权限[other] 文件 - rwx rwx rwx 目录 d rwx rwx rwx 修改权限 方法一：chmod 用户+操作+权限 文件 用户部分： \u0026ldquo;u\u0026rdquo; 表示拥有者 [user]\n\u0026ldquo;g\u0026rdquo; 表示拥有者所在群组 [group]\n\u0026ldquo;o\u0026rdquo; 表示其他用户 [other]\n\u0026ldquo;a\u0026rdquo; 表示全部用户 [all，包含前面三种用户范围]\n若不指定，默认为拥有者权限 \u0026ldquo;u\u0026rdquo;\n操作部分： \u0026ldquo;+\u0026rdquo; 表示增加权限\n\u0026ldquo;-\u0026rdquo; 表示取消权限\n\u0026ldquo;=\u0026rdquo; 表示赋值权限\n权限部分： \u0026ldquo;r\u0026rdquo; 表示可读 [read]\n\u0026ldquo;w\u0026rdquo; 表示可写 [write]\n\u0026ldquo;x\u0026rdquo; 表示可执行权限 [execute]\n文件部分： 指定文件/目录全名\n若不指定，表示操作对象为当前目录下的所有文件\n注： 可以同时使用多种操作符添加和取消权限\n可以使用 \u0026ldquo;,\u0026rdquo; 符号同时对不同用户范围修改权限\n例： 指定文件 \u0026ldquo;a\u0026rdquo; 的初始权限为：-rw-rw-r-x\n将权限改为：rwxr-xrw- 的命令为chmod ug+x,g-w,o+w-x a\n方法二：chmod xxx 文件 [x为数字] 数字和权限对应关系： 每位数字代表对应用户类型所持有权限的代数总和 数字 [xxx] 部分： 三个数字从前到后分别表示 u、g、o 三种用户类型的访问权限 补充： 递归修改目录文件及其子目录中的文件权限类型，可以使用 -R 选项 ","date":"2020-08-20T10:28:53+08:00","permalink":"https://Ocancel.GitHub.io/post/linux-chmod/","title":"Linux chmod"},{"content":" 排序算法 平均时间复杂度 最好情况 最坏情况 空间复杂度 排序方式 稳定性 冒泡排序 O(n2) O(n) O(n2) O(1) 内部排序 稳定 选择排序 O(n2) O(n2) O(n2) O(1) 内部排序 不稳定 插入排序 O(n2) O(n) O(n2) O(1) 内部排序 稳定 希尔排序 O(nlogn) O(nlog2n) O(nlog2n) O(1) 内部排序 不稳定 归并排序 O(nlogn) O(nlogn) O(nlogn) O(n) 外部排序 稳定 快速排序 O(nlogn) O(nlogn) O(n2) O(logn) 内部排序 不稳定 堆排序 O(nlogn) O(nlogn) O(nlogn) O(1) 内部排序 不稳定 计数排序 O(n+k) O(n+k) O(n+k) O(k) 外部排序 稳定 桶排序 O(n+k) O(n+k) O(n2) O(n+k) 外部排序 稳定 基数排序 O(n*k) O(n*k) O(n*k) O(n+k) 外部排序 稳定 稳定性：在原序列中，r[i]=r[j]，且r[i]在r[j]之前，而在排序后的序列中，r[i]仍在r[j]之前，则称这种排序算法是稳定的。 排序方式：\n内部排序：指待排序列完全存放在内存中所进行的排序过程。 外部排序：指待排序记录存储在外存储器上，无法一次全部放入内存，期间需要内存与外存储器进行多次数据交换，最终完成的排序过程。 实现 设待排序序列长度为N\n冒泡排序｜Bubble Sort 基础算法 思想\n比较相邻两个元素，如果前面的元素大于后面的元素，就将这两个元素交换。 对数组的第0个元素到N-1个元素进行一次遍历后，最大的一个元素就移动到数组第N-1个位置。 N=N-1，如果N不为0就重复前面二步，否则排序完成。 实现\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 /** * @param arr */ public static void bubbleSort(int[] arr) { int i, j; for (i = 0; i \u0026lt; arr.length; i++) { for (j = 1; j \u0026lt; arr.length - i; j++) { if (arr[j - 1] \u0026gt; arr[j]) { int temp = arr[j - 1]; arr[j - 1] = arr[j]; arr[j] = temp; } } } } 优化算法 思想\n基于基础算法，若有一次遍历中未发生数据交换，则排序已经完成。\n实现\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 /** * @param arr */ public static void bubbleSort(int[] arr) { int j, k = arr.length; boolean flag = true; while (flag) { flag = false; for (j = 1; j \u0026lt; k; j++) { if (arr[j - 1] \u0026gt; arr[j]) { int temp = arr[j - 1]; arr[j - 1] = arr[j]; arr[j] = temp; flag = true; } } k--; } } 选择排序｜Selection Sort 思想\n对数组进行一次遍历，找到最小元素，并与待排序序列首个元素交换。 N=N-1，若N\u0026gt;0，重复第一步，若N=0，排序完成。 实现\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 /** * @param arr */ public static void selectionSort(int[] arr) { for (int i = 0; i \u0026lt; arr.length - 1; i++) { int minIndex = i; for (int j = i + 1; j \u0026lt; arr.length; j++) { if (arr[j] \u0026lt; arr[minIndex]) { minIndex = j; } } int temp = arr[i]; arr[i] = arr[minIndex]; arr[minIndex] = temp; } } 插入排序｜Insertion Sort 思想\n在待排序序列中取出一个元素，遍历已排序序列，将元素插入到合适位置。 N=N-1，若N\u0026gt;0，重复第一步，若N=0，排序完成。 实现\n1 2 3 4 5 6 7 8 9 10 11 12 13 /** * @param arr */ public static void insertionSort(int[] arr) { int n = arr.length; for (int i = 1; i \u0026lt; n; i++) { for (int j = i; j \u0026gt; 0 \u0026amp;\u0026amp; arr[j] \u0026lt; arr[j - 1]; j--) { int temp = arr[j]; arr[j] = arr[j - 1]; arr[j - 1] = temp; } } } 希尔排序｜Shell Sort 思想\n希尔排序是把记录按下标的一定增量分组，对每组使用直接插入排序算法排序；随着增量逐渐减少，每组包含的关键词越来越多，当增量减至1时，整个文件恰被分成一组，算法便终止。\n实现\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 /** * @param arr */ public static void shellSort(int[] arr) { int length = arr.length; int temp; for (int step = length / 2; step \u0026gt;= 1; step /= 2) { for (int i = step; i \u0026lt; length; i++) { temp = arr[i]; int j = i - step; while (j \u0026gt;= 0 \u0026amp;\u0026amp; arr[j] \u0026gt; temp) { arr[j + step] = arr[j]; j -= step; } arr[j + step] = temp; } } } 归并排序｜Marge Sort 思想\n分治法：\n分割：递归地把当前序列平均分割成两半。 集成：在保持元素顺序的同时将上一步得到的子序列集成到一起（归并）。 实现\n递归版 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 /** * @param arr */ static void mergeSortRecursive(int[] arr, int[] result, int start, int end) { if (start \u0026gt;= end) return; int len = end - start, mid = (len \u0026gt;\u0026gt; 1) + start; int start1 = start, end1 = mid; int start2 = mid + 1, end2 = end; mergeSortRecursive(arr, result, start1, end1); mergeSortRecursive(arr, result, start2, end2); int k = start; while (start1 \u0026lt;= end1 \u0026amp;\u0026amp; start2 \u0026lt;= end2) result[k++] = arr[start1] \u0026lt; arr[start2] ? arr[start1++] : arr[start2++]; while (start1 \u0026lt;= end1) result[k++] = arr[start1++]; while (start2 \u0026lt;= end2) result[k++] = arr[start2++]; for (k = start; k \u0026lt;= end; k++) arr[k] = result[k]; } public static void mergeSort(int[] arr) { int len = arr.length; int[] result = new int[len]; mergeSortRecursive(arr, result, 0, len - 1); } 迭代版 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 public static void mergeSort(int[] arr) { int[] orderedArr = new int[arr.length]; for (int i = 2; i \u0026lt; arr.length * 2; i *= 2) { for (int j = 0; j \u0026lt; (arr.length + i - 1) / i; j++) { int left = i * j; int mid = left + i / 2 \u0026gt;= arr.length ? (arr.length - 1) : (left + i / 2); int right = i * (j + 1) - 1 \u0026gt;= arr.length ? (arr.length - 1) : (i * (j + 1) - 1); int start = left, l = left, m = mid; while (l \u0026lt; mid \u0026amp;\u0026amp; m \u0026lt;= right) { if (arr[l] \u0026lt; arr[m]) { orderedArr[start++] = arr[l++]; } else { orderedArr[start++] = arr[m++]; } } while (l \u0026lt; mid) orderedArr[start++] = arr[l++]; while (m \u0026lt;= right) orderedArr[start++] = arr[m++]; System.arraycopy(orderedArr, left, arr, left, right - left + 1); } } } 快速排序｜Quick Sort 思想\n分治法：\n挑选基准值：从数列中挑出一个元素，称为“基准”。 分割：重新排序数列，所有比基准值小的元素摆放在基准前面，所有比基准值大的元素摆在基准后面（与基准值相等的数可以到任何一边）。 递归排序子序列：递归地将小于基准值元素的子序列和大于基准值元素的子序列排序。 实现\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 /** * @param arr * @param low * @param high */ static int partition(int[] arr, int low, int high) { int pivot = arr[high]; int pointer = low; for (int i = low; i \u0026lt; high; i++) { if (arr[i] \u0026lt;= pivot) { int temp = arr[i]; arr[i] = arr[pointer]; array[pointer] = temp; pointer++; } } int temp = arr[pointer]; arr[pointer] = arr[high]; arr[high] = temp; return pointer; } public static void quickSort(int[] arr, int low, int high) { if (low \u0026lt; high) { int position = partition(arr, low, high); quickSort(arr, low, position - 1); quickSort(arr, position + 1, high); } } 堆排序｜Heap Sort 思想\n建立一个堆H[0...n-1]。 把堆首（最大值）和堆尾互换。 把堆的尺寸缩小1，把新的数组顶端数据调整到相应位置。 重复步骤2，直到堆的尺寸为1。 实现\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 /** * @param arr */ public void heapSort(int[] arr) { int len = arr.length - 1; int beginIndex = (arr.length \u0026gt;\u0026gt; 1) - 1; for (int i = beginIndex; i \u0026gt;= 0; i--) maxHeapify(i, len); for (int i = len; i \u0026gt; 0; i--) { swap(0, i); maxHeapify(0, i - 1); } } private void swap(int i, int j) { int temp = arr[i]; arr[i] = arr[j]; arr[j] = temp; } private void maxHeapify(int index, int len) { int li = (index \u0026lt;\u0026lt; 1) + 1; int ri = li + 1; int cMax = li; if (li \u0026gt; len) return; if (ri \u0026lt;= len \u0026amp;\u0026amp; arr[ri] \u0026gt; arr[li]) cMax = ri; if (arr[cMax] \u0026gt; arr[index]) { swap(cMax, index); maxHeapify(cMax, len); } } 计数排序｜Count Sort 思想\n找出待排序数组中最大和最小的元素。 统计数组中每个值为i 的元素出现的次数，存入计数数组C的第i-minValue项。 对所有的计数累加。 反向填充数组：将每个元素i放在新数组的第C[i]项，每放一个元素就将C[i]减去1。 实现\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 /** * @param arr * @return b */ public static int[] countSort(int[] arr){ int b[] = new int[arr.length]; int max = arr[0], min = arr[0]; for(int i : arr){ if(i \u0026gt; max){ max = i; } if(i \u0026lt; min){ min = i; } } int k = max - min + 1; int c[] = new int[k]; for(int i = 0; i \u0026lt; arr.length; ++i){ c[a[i] - min] += 1; } for(int i = 1; i \u0026lt; c.length; ++i){ c[i] = c[i] + c[i - 1]; } for(int i = arr.length - 1; i \u0026gt;= 0; --i){ b[--c[arr[i] - min]] = arr[i]; } return b; } 桶排序｜Bucket Sort 思想\n设置一个定量的数组当作空桶。 遍历序列，并把元素放到对应的桶去。 对每一个非空桶进行排序。 再将非空桶中元素放回原队列。 实现\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 /** * @param arr */ public void bucketSort(int[] arr) { int max = arr[0], min = arr[0]; for (int a : arr) { if (max \u0026lt; a) max = a; if (min \u0026gt; a) min = a; } int bucketNum = max / 10 - min / 10 + 1; List buckList = new ArrayList\u0026lt;List\u0026lt;Integer\u0026gt;\u0026gt;(); for (int i = 1; i \u0026lt;= bucketNum; i++) { buckList.add(new ArrayList\u0026lt;Integer\u0026gt;()); } for (int i = 0; i \u0026lt; arr.length; i++) { int index = indexFor(arr[i], min, 10); ((ArrayList\u0026lt;Integer\u0026gt;) buckList.get(index)).add(arr[i]); } ArrayList\u0026lt;Integer\u0026gt; bucket = null; int index = 0; for (int i = 0; i \u0026lt; bucketNum; i++) { bucket = (ArrayList\u0026lt;Integer\u0026gt;) buckList.get(i); insertSort(bucket); for (int k : bucket) { arr[index++] = k; } } } private int indexFor(int a, int min, int step) { return (a - min) / step; } private void insertSort(List\u0026lt;Integer\u0026gt; bucket) { for (int i = 1; i \u0026lt; bucket.size(); i++) { int temp = bucket.get(i); int j = i - 1; for (; j \u0026gt;= 0 \u0026amp;\u0026amp; bucket.get(j) \u0026gt; temp; j--) { bucket.set(j + 1, bucket.get(j)); } bucket.set(j + 1, temp); } } 基数排序｜Radix Sort 思想\n将所有待比较数值（正整数）统一为同样的数位长度，数位较短的数前面补零。 从最低位开始，依次进行一次排序。 排序完成以后，数列就变成一个有序序列。 实现\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 /** * @param arr */ public static void radixSort(int[] arr) { if (null == arr || 0 == arr.length) return; int k = maxbit(arr); int radix = 1; for (int i = 0; i \u0026lt; k; i++) { countingSort(arr, radix); radix *= 10; } } private static int maxbit(int[] arr) { int max = arr[0]; for (int i = 1; i \u0026lt; arr.length; i++) max = max \u0026lt; arr[i] ? arr[i] : max; int d = 1; while ((max = max / 10) \u0026gt; 0) d++; return d; } public static void countingSort(int[] arr, int radix) { int[] counts = new int[10]; int len = arr.length; int[] buffer = new int[len]; for (int i = 0; i \u0026lt; len; i++) counts[(arr[i] / radix) % 10]++; for (int i = 1; i \u0026lt; counts.length; i++) counts[i] = counts[i] + counts[i - 1]; for (int i = len - 1; i \u0026gt;= 0; i--) { buffer[counts[(arr[i] / radix ) % 10] - 1] = arr[i]; counts[(arr[i] / radix) % 10] = counts[(arr[i] / radix) % 10] - 1; } for (int i = 0; i \u0026lt; len; i++) arr[i] = buffer[i]; } ","date":"2020-08-09T17:02:45+08:00","permalink":"https://Ocancel.GitHub.io/post/sorting-algorithm/","title":"Sorting Algorithm"},{"content":"I. 开闭原则｜Open-Closed Principle｜OCP 对扩展开放，对修改关闭。\nII. 依赖倒置原则｜Dependence Inversion Principle｜DIP 高层模块不应该依赖底层模块，二者都应该依赖其抽象。 抽象不应该依赖细节，细节应该依赖抽象。\nIII. 单一职责原则｜Simple Responsibility Pinciple｜SRP 不要存在多于一个导致类变更的原因。\nIV. 接口隔离原则｜Interface Segregation Principle｜ISP 使用多个专用接口，不使用单一的总接口。\nV. 最少知道原则｜Least Knowledge Principle｜LKP 一个对象应该对其他对象保持最少的了解。\nVI. 里氏替换原则｜Liskov Substitution Principle｜LSP 若对于任意的类型为T1的对象O1，都有类型为T2的对象O2，使得以T1定义的所有程序P在所有的对象O1都替换成O2时，程序P的行为没有发生变化，则类型T2是类型T1的子类型。\n引申含义：\n子类可以扩展父类的功能，但不能改变父类原有的功能。\nVII. 合成复用原则｜Composite / Aggregate Reuse Principle｜CARP 尽量使用对象组合/聚合而不是继承关系达到软件复用的目的。 白箱复用： 指继承，把所有的实现细节暴露给子类。 黑箱复用： 指组合/聚合，无法获取类以外的实现细节。\n总结 设计原则是设计模式的基础，不要求代码完全遵循设计原则，适当的使用设计原则，不要刻意追求完美。\n","date":"2020-07-02T15:31:36+08:00","permalink":"https://Ocancel.GitHub.io/post/design-principle/","title":"Design Principle"}]